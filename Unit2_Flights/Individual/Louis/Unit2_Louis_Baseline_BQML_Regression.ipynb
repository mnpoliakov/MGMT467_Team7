{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI11d5RL/OJ4pCb60ef0JC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnpoliakov/MGMT467_Team7/blob/main/Unit2_Flights/Individual/Louis/Unit2_Louis_Baseline_BQML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c294930",
        "outputId": "9658fa23-0d7d-4957-9d8e-1b661a49b4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BQ Project: mgmt467-71800\n",
            "Source table: flights_data.flights_raw\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Minimal setup (edit 3 vars) ---\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "\n",
        "PROJECT_ID = \"mgmt467-71800\"      # e.g., mgmt-467-47888\n",
        "REGION     = \"us-central1\"\n",
        "TABLE_PATH = \"flights_data.flights_raw\"   # or your `bigquery-public-data.flights` table/view\n",
        "\n",
        "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
        "os.environ[\"REGION\"]     = REGION\n",
        "bq = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(\"BQ Project:\", PROJECT_ID)\n",
        "print(\"Source table:\", TABLE_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "0e402070",
        "outputId": "bcec9959-9bd2-4388-dd6a-168c5aa9e077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
              "0  2024        1      3          15          5  2024-03-15                9E   \n",
              "1  2024        1      1           7          7  2024-01-07                9E   \n",
              "2  2024        1      2          23          5  2024-02-23                9E   \n",
              "3  2024        1      3          27          3  2024-03-27                9E   \n",
              "4  2024        1      2          12          1  2024-02-12                9E   \n",
              "\n",
              "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
              "0                     20363                          9E      N906XJ  ...   \n",
              "1                     20363                          9E      N326PQ  ...   \n",
              "2                     20363                          9E      N310PQ  ...   \n",
              "3                     20363                          9E      N354CA  ...   \n",
              "4                     20363                          9E      N272PQ  ...   \n",
              "\n",
              "   Div5Airport  Div5AirportID  Div5AirportSeqID  Div5WheelsOn Div5TotalGTime  \\\n",
              "0         None           None              None          None           None   \n",
              "1         None           None              None          None           None   \n",
              "2         None           None              None          None           None   \n",
              "3         None           None              None          None           None   \n",
              "4         None           None              None          None           None   \n",
              "\n",
              "  Div5LongestGTime Div5WheelsOff Div5TailNum  string_field_109  \\\n",
              "0             None          None        None              None   \n",
              "1             None          None        None              None   \n",
              "2             None          None        None              None   \n",
              "3             None          None        None              None   \n",
              "4             None          None        None              None   \n",
              "\n",
              "  string_field_110  \n",
              "0             None  \n",
              "1             None  \n",
              "2             None  \n",
              "3             None  \n",
              "4             None  \n",
              "\n",
              "[5 rows x 111 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d078c6b1-eb6e-4752-930a-f5b0e4ddc1f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>FlightDate</th>\n",
              "      <th>Reporting_Airline</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>IATA_CODE_Reporting_Airline</th>\n",
              "      <th>Tail_Number</th>\n",
              "      <th>...</th>\n",
              "      <th>Div5Airport</th>\n",
              "      <th>Div5AirportID</th>\n",
              "      <th>Div5AirportSeqID</th>\n",
              "      <th>Div5WheelsOn</th>\n",
              "      <th>Div5TotalGTime</th>\n",
              "      <th>Div5LongestGTime</th>\n",
              "      <th>Div5WheelsOff</th>\n",
              "      <th>Div5TailNum</th>\n",
              "      <th>string_field_109</th>\n",
              "      <th>string_field_110</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-03-15</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N906XJ</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2024-01-07</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N326PQ</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-02-23</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N310PQ</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>2024-03-27</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N354CA</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>2024-02-12</td>\n",
              "      <td>9E</td>\n",
              "      <td>20363</td>\n",
              "      <td>9E</td>\n",
              "      <td>N272PQ</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 111 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d078c6b1-eb6e-4752-930a-f5b0e4ddc1f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d078c6b1-eb6e-4752-930a-f5b0e4ddc1f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d078c6b1-eb6e-4752-930a-f5b0e4ddc1f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0c4723e-fc1a-4ef0-a035-63a0b3a7dcfe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0c4723e-fc1a-4ef0-a035-63a0b3a7dcfe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0c4723e-fc1a-4ef0-a035-63a0b3a7dcfe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "preview_sql = f\"SELECT * FROM `{TABLE_PATH}` LIMIT 5\"\n",
        "bq.query(preview_sql).result().to_dataframe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88298de5"
      },
      "source": [
        "# Task\n",
        "Create a pre-departure baseline model using BigQuery ML from the `flights_data.flights_cleaned` table. The model should incorporate 'route' and 'month' as new features, train a logistic regression model with 'carrier', 'route', 'distance', 'day_of_week', and 'month' as features and 'is_arrival_delayed' as the target, then evaluate its performance using AUC and log_loss, generate a confusion matrix at a 0.5 threshold, analyze its calibration, and finally summarize all performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ab37f9"
      },
      "source": [
        "## Prepare Features for Pre-departure Model\n",
        "\n",
        "### Subtask:\n",
        "Create the required features for the pre-departure model, including a 'route' feature (Origin-Dest) and 'month' from FL_DATE, which will then be used to create the baseline model. These operations will be performed directly in BigQuery SQL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4e47064"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct a BigQuery SQL query to create the `route` and `month` features, and select other required columns for the pre-departure model. This query will be stored in a variable for later use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7b1334a"
      },
      "source": [
        "## Prepare Features for Pre-departure Model\n",
        "\n",
        "### Subtask:\n",
        "Create the required features for the pre-departure model, including a 'route' feature (Origin-Dest) and 'month' from FL_DATE, which will then be used to create the baseline model. These operations will be performed directly in BigQuery SQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac4eb458",
        "outputId": "af413614-99ba-49df-b6a5-f887373585de"
      },
      "source": [
        "create_features_sql = f\"\"\"SELECT\n",
        "    ReportingAirline,\n",
        "    Distance,\n",
        "    DepDelay,\n",
        "    ArrDelay,\n",
        "    Origin,\n",
        "    CONCAT(OriginCityName, '-', DestCityName) AS Route,\n",
        "    Diverted,\n",
        "    Month,\n",
        "    DayOfWeek\n",
        "FROM\n",
        "    `{TABLE_PATH}`\n",
        "WHERE\n",
        "    Diverted IS 1.0\n",
        "\"\"\"\n",
        "\n",
        "print(create_features_sql)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "    ReportingAirline,\n",
            "    Distance,\n",
            "    DepDelay,\n",
            "    ArrDelay,\n",
            "    Origin,\n",
            "    CONCAT(OriginCityName, '-', DestCityName) AS Route,\n",
            "    Diverted,\n",
            "    Month,\n",
            "    DayOfWeek\n",
            "FROM\n",
            "    `flights_data.flights_cleaned`\n",
            "WHERE\n",
            "    Diverted IS 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12971652"
      },
      "source": [
        "### Train Pre-departure Baseline Model\n",
        "\n",
        "#### Subtask:\n",
        "Train a BigQuery ML logistic regression model using the prepared features (`carrier`, `route`, `distance`, `day_of_week`, and `month`) and `is_arrival_delayed` as the target variable.\n",
        "\n",
        "#### Instructions:\n",
        "1. Construct a BigQuery SQL query to create a logistic regression model named `pre_departure_baseline_model` within a specified dataset. This model should use the `create_features_sql` as its training data.\n",
        "2. Specify the model options, including `MODEL_TYPE='LOGISTIC_REG'` and `INPUT_LABEL_COLS=['is_arrival_delayed']`.\n",
        "3. Store this SQL query in a Python variable, for example, `model_training_sql`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66fbe7aa"
      },
      "source": [
        "**Reasoning**:\n",
        "To train the BigQuery ML model, I will construct a SQL query using the `CREATE MODEL` statement. This query will specify the model type, input label column, and use the previously defined `create_features_sql` as the training data, storing the resulting query in the `model_training_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4a2c729",
        "outputId": "7a48d466-82ad-43d9-fa14-129aa1bc5787"
      },
      "source": [
        "model_training_sql = f\"\"\"CREATE OR REPLACE MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`\n",
        "OPTIONS(\n",
        "    model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['Diverted']\n",
        ")\n",
        "AS\n",
        "{create_features_sql}\n",
        "\"\"\"\n",
        "\n",
        "print(model_training_sql)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE OR REPLACE MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`\n",
            "OPTIONS(\n",
            "    model_type='LOGISTIC_REG',\n",
            "    input_label_cols=['Diverted']\n",
            ")\n",
            "AS\n",
            "SELECT\n",
            "    ReportingAirline,\n",
            "    Distance,\n",
            "    DepDelay,\n",
            "    ArrDelay,\n",
            "    Origin,\n",
            "    CONCAT(OriginCityName, '-', DestCityName) AS Route,\n",
            "    Diverted,\n",
            "    Month,\n",
            "    DayOfWeek\n",
            "FROM\n",
            "    `flights_data.flights_cleaned`\n",
            "WHERE\n",
            "    Diverted IS 1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5d17d2f"
      },
      "source": [
        "# Task\n",
        "Prepare features for the pre-departure model by modifying the `create_features_sql` to select `ReportingAirline` as `carrier`, `Distance`, `CONCAT(OriginCityName, '-', DestCityName)` as `route`, `Month`, `DayOfWeek`, and `Diverted` from the `flights_data.flights_raw` table, including all rows where `Diverted` is not null."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2c6628c"
      },
      "source": [
        "## Prepare Features for Pre-departure Model (Revised)\n",
        "\n",
        "### Subtask:\n",
        "Refine the `create_features_sql` to select only schedule-level features and the target variable from the raw data, including all rows where `Diverted` is not null.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b74fb6c4"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to update the `create_features_sql` variable with the refined SQL query as per the instructions, changing the FROM clause, SELECT columns with aliases, and the WHERE clause.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a80d0240",
        "outputId": "44765078-3c7a-483b-db34-663c64365ee2"
      },
      "source": [
        "create_features_sql = f\"\"\"SELECT\n",
        "    Reporting_Airline AS carrier,\n",
        "    Distance,\n",
        "    CONCAT(Origin, '-', Dest) AS route,\n",
        "    Month,\n",
        "    DayOfWeek,\n",
        "    Diverted\n",
        "FROM\n",
        "    `flights_data.flights_raw`\n",
        "WHERE\n",
        "    Diverted IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "print(create_features_sql)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6625001"
      },
      "source": [
        "## Create BigQuery ML Model A (Pre-departure Baseline)\n",
        "\n",
        "### Subtask:\n",
        "Train a BigQuery ML logistic regression model using `ML.CREATE_MODEL` with 'carrier', 'route', 'distance', 'day_of_week', and 'month' as features, and 'Diverted' as the target variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ceb4b40"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct the SQL query for training the BigQuery ML logistic regression model using the `create_features_sql` as the training data, specifying the model type and input label. This query will be stored in the `model_training_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e089e62f",
        "outputId": "56da27b2-cfaf-434b-a298-cf2233083aa3"
      },
      "source": [
        "model_training_sql = f\"\"\"CREATE OR REPLACE MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`\n",
        "OPTIONS(\n",
        "    model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['Diverted'],\n",
        "    auto_select_all_features=TRUE,\n",
        "    L1_REG=0.1,\n",
        "    LS_INIT_WEIGHTS='AUTO_ZERO'\n",
        ")\n",
        "AS\n",
        "{create_features_sql}\n",
        "\"\"\"\n",
        "\n",
        "print(model_training_sql)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE OR REPLACE MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`\n",
            "OPTIONS(\n",
            "    model_type='LOGISTIC_REG',\n",
            "    input_label_cols=['Diverted'],\n",
            "    auto_select_all_features=TRUE,\n",
            "    L1_REG=0.1,\n",
            "    LS_INIT_WEIGHTS='AUTO_ZERO'\n",
            ")\n",
            "AS\n",
            "SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2b724a5"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the `model_training_sql` using the BigQuery client to train the model as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "5ac1a51a",
        "outputId": "981979de-c648-4aa1-b4b3-eef88451f827"
      },
      "source": [
        "print('Training BigQuery ML model (this may take a few minutes)...')\n",
        "bq.query(model_training_sql).result()\n",
        "print('Model training complete!')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BigQuery ML model (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 unsupported option auto_select_all_features; reason: invalidQuery, location: query, message: unsupported option auto_select_all_features\n\nLocation: US\nJob ID: 6e373565-c9cf-46fe-b12a-c41e813ec279\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4225641773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training BigQuery ML model (this may take a few minutes)...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_training_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model training complete!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1720\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 unsupported option auto_select_all_features; reason: invalidQuery, location: query, message: unsupported option auto_select_all_features\n\nLocation: US\nJob ID: 6e373565-c9cf-46fe-b12a-c41e813ec279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ad8cbd"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `auto_select_all_features` and `LS_INIT_WEIGHTS` are unsupported options for `LOGISTIC_REG` model type in BigQuery ML. I need to remove these invalid options from the `model_training_sql`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8df425cf",
        "outputId": "d1f8ad5a-0e89-43a1-b3e3-afab708fa82b"
      },
      "source": [
        "model_training_sql = f\"\"\"CREATE OR REPLACE MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`\n",
        "OPTIONS(\n",
        "    model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['Diverted'],\n",
        "    L1_REG=0.1\n",
        ")\n",
        "AS\n",
        "{create_features_sql}\n",
        "\"\"\"\n",
        "\n",
        "print(model_training_sql)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE OR REPLACE MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`\n",
            "OPTIONS(\n",
            "    model_type='LOGISTIC_REG',\n",
            "    input_label_cols=['Diverted'],\n",
            "    L1_REG=0.1\n",
            ")\n",
            "AS\n",
            "SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a308e06f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `model_training_sql` has been corrected by removing unsupported options, the next step is to execute this SQL query to train the BigQuery ML model as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6655471",
        "outputId": "97b96bd2-17aa-4dd9-87ae-8e5071727a0b"
      },
      "source": [
        "print('Training BigQuery ML model (this may take a few minutes)...')\n",
        "bq.query(model_training_sql).result()\n",
        "print('Model training complete!')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BigQuery ML model (this may take a few minutes)...\n",
            "Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2852f4e"
      },
      "source": [
        "## Evaluate Model A Performance (AUC, Log_Loss)\n",
        "\n",
        "### Subtask:\n",
        "Use `ML.EVALUATE` to assess the model's performance, focusing on Area Under the Curve (AUC) and log_loss, which are key metrics for classification models. This will provide an initial understanding of the model's predictive power on the diversion risk.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad826114"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct a BigQuery SQL query to evaluate the `pre_departure_baseline_model` using `ML.EVALUATE`, applying the same filtering criteria as used for training data, and store it in the `evaluate_model_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f5aa99b",
        "outputId": "02e8d5b9-de36-4c4a-c083-85950c2eaa96"
      },
      "source": [
        "evaluate_model_sql = f\"\"\"SELECT\n",
        "  * FROM ML.EVALUATE(\n",
        "    MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`,\n",
        "    (SELECT\n",
        "        Reporting_Airline AS carrier,\n",
        "        Distance,\n",
        "        CONCAT(Origin, '-', Dest) AS route,\n",
        "        Month,\n",
        "        DayOfWeek,\n",
        "        Diverted\n",
        "    FROM\n",
        "        `flights_data.flights_raw`\n",
        "    WHERE\n",
        "        Diverted IS NOT NULL\n",
        "    )\n",
        ")\"\"\"\n",
        "\n",
        "print(evaluate_model_sql)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "  * FROM ML.EVALUATE(\n",
            "    MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`,\n",
            "    (SELECT\n",
            "        Reporting_Airline AS carrier,\n",
            "        Distance,\n",
            "        CONCAT(Origin, '-', Dest) AS route,\n",
            "        Month,\n",
            "        DayOfWeek,\n",
            "        Diverted\n",
            "    FROM\n",
            "        `flights_data.flights_raw`\n",
            "    WHERE\n",
            "        Diverted IS NOT NULL\n",
            "    )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91c1d878"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `evaluate_model_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the evaluation metrics as a Pandas DataFrame and display them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03feea64",
        "outputId": "f288a565-ec91-4d7e-c477-8ff97470511a"
      },
      "source": [
        "print('Evaluating BigQuery ML model...')\n",
        "evaluation_results_df = bq.query(evaluate_model_sql).result().to_dataframe()\n",
        "print('Model evaluation complete!')\n",
        "\n",
        "print(evaluation_results_df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating BigQuery ML model...\n",
            "Model evaluation complete!\n",
            "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
            "0   0.227273  0.001052  0.982763  0.002095  0.076178  0.785921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d34b583"
      },
      "source": [
        "## Generate Confusion Matrix for Model A\n",
        "\n",
        "### Subtask:\n",
        "Calculate and display the confusion matrix for Model A at a classification threshold of 0.5 using `ML.CONFUSION_MATRIX`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97ec702"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct a BigQuery SQL query to generate the confusion matrix for the `pre_departure_baseline_model` using `ML.CONFUSION_MATRIX` with a classification threshold of 0.5 and the same input data used for training, storing it in the `confusion_matrix_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f2427a8",
        "outputId": "8c0374f6-23dc-4685-d5e2-34b6f69bef90"
      },
      "source": [
        "confusion_matrix_sql = f\"\"\"SELECT\n",
        "  * FROM ML.CONFUSION_MATRIX(\n",
        "    MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`,\n",
        "    (SELECT\n",
        "        Reporting_Airline AS carrier,\n",
        "        Distance,\n",
        "        CONCAT(Origin, '-', Dest) AS route,\n",
        "        Month,\n",
        "        DayOfWeek,\n",
        "        Diverted\n",
        "    FROM\n",
        "        `flights_data.flights_raw`\n",
        "    WHERE\n",
        "        Diverted IS NOT NULL\n",
        "    ),\n",
        "    STRUCT(0.5 AS threshold)\n",
        ")\"\"\"\n",
        "\n",
        "print(confusion_matrix_sql)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "  * FROM ML.CONFUSION_MATRIX(\n",
            "    MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`,\n",
            "    (SELECT\n",
            "        Reporting_Airline AS carrier,\n",
            "        Distance,\n",
            "        CONCAT(Origin, '-', Dest) AS route,\n",
            "        Month,\n",
            "        DayOfWeek,\n",
            "        Diverted\n",
            "    FROM\n",
            "        `flights_data.flights_raw`\n",
            "    WHERE\n",
            "        Diverted IS NOT NULL\n",
            "    ),\n",
            "    STRUCT(0.5 AS threshold)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3bea28d"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `confusion_matrix_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the confusion matrix as a Pandas DataFrame and display it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad57ab29",
        "outputId": "829b2701-4e5d-4192-8733-81935203f31c"
      },
      "source": [
        "print('Generating confusion matrix...')\n",
        "confusion_matrix_df = bq.query(confusion_matrix_sql).result().to_dataframe()\n",
        "print('Confusion matrix generated!')\n",
        "\n",
        "print(confusion_matrix_df)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating confusion matrix...\n",
            "Confusion matrix generated!\n",
            "   expected_label       _0   _1\n",
            "0             0.0  1629646  102\n",
            "1             1.0    28481   30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation of Confusion Matrix\n",
        "\n",
        "### At a 0.5 threshold):\n",
        "\n",
        "- True Negatives (TN): 1629646 - The model correctly predicted a vast majority of non-diverted flights.\n",
        "- False Positives (FP): 102 - The model incorrectly predicted 102 flights as diverted when they were not. This number is very low, indicating high precision for positive predictions.\n",
        "- False Negatives (FN): 28481 - The model incorrectly predicted 28,481 flights as not diverted when they actually were. This is a significant number, leading to a very low recall for the positive class.\n",
        "- True Positives (TP): 30 - The model correctly identified only 30 actual diversions.\n",
        "\n",
        "The confusion matrix highlights a critical issue: the model's recall for diversions is extremely low (0.001052). While its precision (0.227273) for predicting diversions is higher, the model struggles to identify actual diversion events. This suggests that at a 0.5 threshold, the model is overly cautious and misses most of the positive cases."
      ],
      "metadata": {
        "id": "xxUf8b_TX-bM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0052a7b"
      },
      "source": [
        "## Analyze Model A Calibration\n",
        "\n",
        "### Subtask:\n",
        "Perform an analysis of the model's calibration by comparing predicted probabilities against actual outcomes. This step aims to understand how well the predicted probabilities align with the true likelihood of diversion, providing 2-3 lines of analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74a706f1"
      },
      "source": [
        "**Reasoning**:\n",
        "To analyze the model's calibration, I will construct a BigQuery SQL query using `ML.PREDICT` to get predicted probabilities, then group these predictions into 10 bins using `NTILE` and calculate the average predicted probability and actual diversion rate for each bin. This query will be stored in `calibration_sql`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de8ee057",
        "outputId": "5310caa0-ef1b-4650-e23c-c61ca1a301ac"
      },
      "source": [
        "calibration_sql = f\"\"\"WITH Predictions AS (\n",
        "    SELECT\n",
        "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
        "        Diverted\n",
        "    FROM\n",
        "        ML.PREDICT(\n",
        "            MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`,\n",
        "            (SELECT\n",
        "                Reporting_Airline AS carrier,\n",
        "                Distance,\n",
        "                CONCAT(Origin, '-', Dest) AS route,\n",
        "                Month,\n",
        "                DayOfWeek,\n",
        "                Diverted\n",
        "            FROM\n",
        "                `flights_data.flights_raw`\n",
        "            WHERE\n",
        "                Diverted IS NOT NULL\n",
        "            )\n",
        "        )\n",
        ")\n",
        "SELECT\n",
        "    NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
        "    AVG(predicted_probability) AS avg_predicted_probability,\n",
        "    AVG(Diverted) AS actual_diversion_rate\n",
        "FROM\n",
        "    Predictions\n",
        "GROUP BY\n",
        "    probability_bin\n",
        "ORDER BY\n",
        "    probability_bin\n",
        "\"\"\"\n",
        "\n",
        "print(calibration_sql)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH Predictions AS (\n",
            "    SELECT\n",
            "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
            "        Diverted\n",
            "    FROM\n",
            "        ML.PREDICT(\n",
            "            MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`,\n",
            "            (SELECT\n",
            "                Reporting_Airline AS carrier,\n",
            "                Distance,\n",
            "                CONCAT(Origin, '-', Dest) AS route,\n",
            "                Month,\n",
            "                DayOfWeek,\n",
            "                Diverted\n",
            "            FROM\n",
            "                `flights_data.flights_raw`\n",
            "            WHERE\n",
            "                Diverted IS NOT NULL\n",
            "            )\n",
            "        )\n",
            ")\n",
            "SELECT\n",
            "    NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
            "    AVG(predicted_probability) AS avg_predicted_probability,\n",
            "    AVG(Diverted) AS actual_diversion_rate\n",
            "FROM\n",
            "    Predictions\n",
            "GROUP BY\n",
            "    probability_bin\n",
            "ORDER BY\n",
            "    probability_bin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfdcfa3a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `calibration_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the calibration metrics as a Pandas DataFrame and display them, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eb12942",
        "outputId": "5aa6cf05-0808-4f94-9537-9dbdb18cc46d"
      },
      "source": [
        "calibration_sql = f\"\"\"WITH Predictions AS (\n",
        "    SELECT\n",
        "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
        "        Diverted\n",
        "    FROM\n",
        "        ML.PREDICT(\n",
        "            MODEL `{PROJECT_ID}.flights_data.pre_departure_baseline_model`,\n",
        "            (SELECT\n",
        "                Reporting_Airline AS carrier,\n",
        "                Distance,\n",
        "                CONCAT(Origin, '-', Dest) AS route,\n",
        "                Month,\n",
        "                DayOfWeek,\n",
        "                Diverted\n",
        "            FROM\n",
        "                `flights_data.flights_raw`\n",
        "            WHERE\n",
        "                Diverted IS NOT NULL\n",
        "            )\n",
        "        )\n",
        "),\n",
        "BinnedPredictions AS (\n",
        "    SELECT\n",
        "        NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
        "        predicted_probability,\n",
        "        Diverted\n",
        "    FROM\n",
        "        Predictions\n",
        ")\n",
        "SELECT\n",
        "    probability_bin,\n",
        "    AVG(predicted_probability) AS avg_predicted_probability,\n",
        "    AVG(Diverted) AS actual_diversion_rate\n",
        "FROM\n",
        "    BinnedPredictions\n",
        "GROUP BY\n",
        "    probability_bin\n",
        "ORDER BY\n",
        "    probability_bin\n",
        "\"\"\"\n",
        "\n",
        "print(calibration_sql)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH Predictions AS (\n",
            "    SELECT\n",
            "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
            "        Diverted\n",
            "    FROM\n",
            "        ML.PREDICT(\n",
            "            MODEL `mgmt467-71800.flights_data.pre_departure_baseline_model`,\n",
            "            (SELECT\n",
            "                Reporting_Airline AS carrier,\n",
            "                Distance,\n",
            "                CONCAT(Origin, '-', Dest) AS route,\n",
            "                Month,\n",
            "                DayOfWeek,\n",
            "                Diverted\n",
            "            FROM\n",
            "                `flights_data.flights_raw`\n",
            "            WHERE\n",
            "                Diverted IS NOT NULL\n",
            "            )\n",
            "        )\n",
            "),\n",
            "BinnedPredictions AS (\n",
            "    SELECT\n",
            "        NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
            "        predicted_probability,\n",
            "        Diverted\n",
            "    FROM\n",
            "        Predictions\n",
            ")\n",
            "SELECT\n",
            "    probability_bin,\n",
            "    AVG(predicted_probability) AS avg_predicted_probability,\n",
            "    AVG(Diverted) AS actual_diversion_rate\n",
            "FROM\n",
            "    BinnedPredictions\n",
            "GROUP BY\n",
            "    probability_bin\n",
            "ORDER BY\n",
            "    probability_bin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "966058d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `calibration_sql` has been corrected to avoid using an analytic function in the `GROUP BY` clause, I need to execute this SQL query using the BigQuery client to get the calibration metrics as a Pandas DataFrame and display them, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52149ba4",
        "outputId": "aa75fa1c-a345-410d-e88f-0d7225125b2d"
      },
      "source": [
        "print('Analyzing model calibration...')\n",
        "calibration_df = bq.query(calibration_sql).result().to_dataframe()\n",
        "print('Model calibration analysis complete!')\n",
        "\n",
        "print(calibration_df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing model calibration...\n",
            "Model calibration analysis complete!\n",
            "   probability_bin  avg_predicted_probability  actual_diversion_rate\n",
            "0                1                   0.939825               0.083425\n",
            "1                2                   0.968772               0.026425\n",
            "2                3                   0.978592               0.014931\n",
            "3                4                   0.983946               0.011241\n",
            "4                5                   0.987640               0.007900\n",
            "5                6                   0.990490               0.006175\n",
            "6                7                   0.992681               0.007417\n",
            "7                8                   0.994541               0.006724\n",
            "8                9                   0.996212               0.005644\n",
            "9               10                   0.997795               0.002050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e724ace"
      },
      "source": [
        "The calibration analysis shows that for lower probability bins (e.g., bin 1), the model's predicted probability (0.939825) is significantly higher than the actual diversion rate (0.083425), indicating overconfidence in predicting non-diversion. As the predicted probability increases across the bins, the model consistently overestimates the likelihood of non-diversion, with predicted probabilities often much higher than the observed actual diversion rates. This suggests the model is poorly calibrated and tends to be overly confident in its low-probability predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6bea89f"
      },
      "source": [
        "## Summarize Baseline Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of Model A's performance, including the AUC, log_loss, insights from the confusion matrix, and observations on calibration. This will establish the initial no-real-time baseline for diversion risk.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "560cb89d"
      },
      "source": [
        "### Model A Performance Summary (Pre-departure Baseline)\n",
        "\n",
        "This summary establishes the initial no-real-time baseline for diversion risk using the `pre_departure_baseline_model`.\n",
        "\n",
        "**1. AUC and Log_Loss:**\n",
        "\n",
        "*   **AUC:** The model achieved an Area Under the Curve (AUC) of `0.785921`. An AUC of approximately 0.79 indicates that the model has a decent ability to distinguish between flights that will be diverted and those that will not. However, it's not excellent, suggesting there's room for improvement.\n",
        "*   **Log_Loss:** The log_loss is `0.076178`. A lower log_loss value is better, indicating that the model's predicted probabilities are close to the actual outcomes. While this value seems low, it must be considered in the context of a highly imbalanced dataset (very few diversions).\n",
        "\n",
        "**2. Confusion Matrix (at a 0.5 threshold):**\n",
        "\n",
        "*   **True Negatives (TN):** `1629646` - The model correctly predicted a vast majority of non-diverted flights.\n",
        "*   **False Positives (FP):** `102` - The model incorrectly predicted 102 flights as diverted when they were not. This number is very low, indicating high precision for positive predictions.\n",
        "*   **False Negatives (FN):** `28481` - The model incorrectly predicted 28,481 flights as not diverted when they actually were. This is a significant number, leading to a very low recall for the positive class.\n",
        "*   **True Positives (TP):** `30` - The model correctly identified only 30 actual diversions.\n",
        "\n",
        "The confusion matrix highlights a critical issue: the model's **recall** for diversions is extremely low (`0.001052`). While its precision (`0.227273`) for predicting diversions is higher, the model struggles to identify actual diversion events. This suggests that at a 0.5 threshold, the model is overly cautious and misses most of the positive cases.\n",
        "\n",
        "**3. Calibration Analysis:**\n",
        "\n",
        "The calibration analysis (comparing `avg_predicted_probability` with `actual_diversion_rate` across probability bins) shows discrepancies:\n",
        "\n",
        "*   For lower probability bins (e.g., `probability_bin` 1: average predicted `0.939825`, actual `0.083425`), the model is significantly overconfident, predicting very high probabilities while the actual diversion rate is much lower. This trend continues across most bins, where the `avg_predicted_probability` is considerably higher than the `actual_diversion_rate`.\n",
        "*   Even in the highest probability bin (bin 10: average predicted `0.997795`, actual `0.002050`), the actual diversion rate remains very low, indicating that even when the model is most confident, the event of diversion is still rare, and the model's high confidence doesn't perfectly align with the actual observed rate.\n",
        "\n",
        "Overall, the model is **over-confident** in its predictions, especially for the positive class (diversion), as its predicted probabilities are consistently higher than the observed actual diversion rates. This suggests the model's probabilities are not well-calibrated.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "This initial pre-departure baseline model demonstrates a moderate discriminative ability (AUC ~0.79) but struggles significantly with **recall** for diversion events, identifying only a tiny fraction of actual diversions. Furthermore, the model exhibits poor **calibration**, tending to be over-confident in its probability estimates. While it serves as a starting point, its practical utility as an early warning system for diversions is limited due to the high number of false negatives and poor calibration. Future iterations should aim to improve recall and calibration, potentially through techniques like resampling, cost-sensitive learning, or threshold adjustment, to make it a more effective tool for diversion risk assessment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77394d3c"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `create_features_sql` was successfully modified to select `Reporting_Airline` as `carrier`, `Distance`, `CONCAT(Origin, '-', Dest)` as `route`, `Month`, `DayOfWeek`, and `Diverted` from `flights_data.flights_raw`, including all rows where `Diverted` is not null.\n",
        "*   A BigQuery ML logistic regression model, named `flights_data.pre_departure_baseline_model`, was successfully trained. Initial training attempts failed due to unsupported options (`auto_select_all_features`, `LS_INIT_WEIGHTS`) for the `LOGISTIC_REG` model type, which were subsequently removed.\n",
        "*   The model achieved an Area Under the Curve (AUC) of 0.785921 and a log\\_loss of 0.076178.\n",
        "*   At a classification threshold of 0.5, the confusion matrix revealed: 1,629,646 True Negatives, 102 False Positives, 28,481 False Negatives, and only 30 True Positives. This indicates an extremely low recall for actual diversions (0.001052).\n",
        "*   The model is poorly calibrated, consistently overestimating the probability of non-diversion. For instance, in the lowest probability bin, the average predicted probability was 0.939825, while the actual diversion rate was 0.083425.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   While the model shows moderate discriminative ability (AUC $\\sim$0.79), its practical utility as an early warning system for diversions is significantly limited by its extremely low recall (missing most actual diversions) and poor calibration (over-confidence in predictions).\n",
        "*   Future model development should prioritize improving recall and calibration, potentially through techniques such as resampling, cost-sensitive learning, or adjusting the classification threshold, to make it a more effective tool for diversion risk assessment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7bcaf74"
      },
      "source": [
        "# Task\n",
        "Prepare features for the engineered model by creating a BigQuery SQL query that selects 'carrier' (as `Reporting_Airline`), 'route' (as `CONCAT(Origin, '-', Dest)`), 'distance' (as `Distance`), 'day_of_week' (as `DayOfWeek`), 'month' (as `Month`), and a new bucketized `dep_delay` feature (categorized as 'no_delay', 'short_delay', 'medium_delay', or 'long_delay' based on the `DepDelay` column) from the `flights_data.flights_raw` table, with 'Diverted' as the target variable, including all rows where `Diverted` is not null."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ca9eb7d"
      },
      "source": [
        "## Prepare Features for Engineered Model\n",
        "\n",
        "### Subtask:\n",
        "Construct a BigQuery SQL query to prepare features for the engineered model. This will include 'carrier', 'route' (Origin-Dest), 'distance', 'day_of_week', and 'month' (as used in the baseline), plus a new feature: dep_delay bucketized into categories (e.g., 'no_delay', 'short_delay', 'medium_delay', 'long_delay'). The target variable will remain 'Diverted'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f49e5eab"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct a BigQuery SQL query to prepare features for the engineered model as instructed, including the new 'dep_delay_bucket' feature using a CASE statement, and store it in the `create_engineered_features_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8d2413a",
        "outputId": "96909a0d-d8e6-4610-bf7e-ba0da8468298"
      },
      "source": [
        "create_engineered_features_sql = f\"\"\"SELECT\n",
        "    Reporting_Airline AS carrier,\n",
        "    Distance,\n",
        "    CONCAT(Origin, '-', Dest) AS route,\n",
        "    Month,\n",
        "    DayOfWeek,\n",
        "    CASE\n",
        "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
        "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
        "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
        "        ELSE 'long_delay'\n",
        "    END AS dep_delay_bucket,\n",
        "    Diverted\n",
        "FROM\n",
        "    `flights_data.flights_raw`\n",
        "WHERE\n",
        "    Diverted IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "print(create_engineered_features_sql)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    CASE\n",
            "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
            "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
            "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
            "        ELSE 'long_delay'\n",
            "    END AS dep_delay_bucket,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eed1770"
      },
      "source": [
        "## Create BigQuery ML Engineered Model\n",
        "\n",
        "### Subtask:\n",
        "Train a new BigQuery ML logistic regression model, named `pre_departure_engineered_model`, using the newly prepared features. The model will use the bucketized `dep_delay` feature alongside the existing schedule-level features, with 'Diverted' as the target variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00b55186"
      },
      "source": [
        "**Reasoning**:\n",
        "\n",
        "To train the BigQuery ML engineered model, I will construct a SQL query using the `CREATE MODEL` statement. This query will specify the model type, input label column, and use the previously defined `create_engineered_features_sql` as the training data, storing the resulting query in the `engineered_model_training_sql` variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2077017c"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct the BigQuery SQL query to create the engineered logistic regression model using the `create_engineered_features_sql` and store it in `engineered_model_training_sql`, then print it for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c4eb24",
        "outputId": "ede50a50-b4ed-421e-f0bd-17964c3876f6"
      },
      "source": [
        "engineered_model_training_sql = f\"\"\"CREATE OR REPLACE MODEL `{PROJECT_ID}.flights_data.pre_departure_engineered_model`\n",
        "OPTIONS(\n",
        "    model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['Diverted']\n",
        ")\n",
        "AS\n",
        "{create_engineered_features_sql}\n",
        "\"\"\"\n",
        "\n",
        "print(engineered_model_training_sql)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CREATE OR REPLACE MODEL `mgmt467-71800.flights_data.pre_departure_engineered_model`\n",
            "OPTIONS(\n",
            "    model_type='LOGISTIC_REG',\n",
            "    input_label_cols=['Diverted']\n",
            ")\n",
            "AS\n",
            "SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    CASE\n",
            "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
            "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
            "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
            "        ELSE 'long_delay'\n",
            "    END AS dep_delay_bucket,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60e9d337"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `engineered_model_training_sql` has been constructed, I need to execute this SQL query using the BigQuery client to train the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "892b7e0b",
        "outputId": "3660b859-3c63-4916-8784-10f62cc5cf74"
      },
      "source": [
        "print('Training BigQuery ML engineered model (this may take a few minutes)...')\n",
        "bq.query(engineered_model_training_sql).result()\n",
        "print('Engineered model training complete!')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BigQuery ML engineered model (this may take a few minutes)...\n",
            "Engineered model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61c8840a"
      },
      "source": [
        "## Evaluate Engineered Model Performance (AUC, Log_Loss)\n",
        "\n",
        "### Subtask:\n",
        "Use `ML.EVALUATE` to assess the engineered model's performance, focusing on Area Under the Curve (AUC) and log_loss. This will allow for comparison with the baseline model and provide insights into the impact of the new `dep_delay_bucket` feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bbdb1f"
      },
      "source": [
        "<b>Reasoning</b>:\n",
        "Construct a BigQuery SQL query to evaluate the `pre_departure_engineered_model` using `ML.EVALUATE`, applying the same feature engineering logic as used for training data, and store it in the `evaluate_engineered_model_sql` variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b453a942"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct the BigQuery SQL query to evaluate the engineered logistic regression model using the `create_engineered_features_sql` and store it in `evaluate_engineered_model_sql`, then print it for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09cefb7c",
        "outputId": "04a1c0f0-1cd7-40e8-b145-5b36028f48ad"
      },
      "source": [
        "evaluate_engineered_model_sql = f\"\"\"SELECT\n",
        "  * FROM ML.EVALUATE(\n",
        "    MODEL `{PROJECT_ID}.flights_data.pre_departure_engineered_model`,\n",
        "    ({create_engineered_features_sql})\n",
        ")\"\"\"\n",
        "\n",
        "print(evaluate_engineered_model_sql)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "  * FROM ML.EVALUATE(\n",
            "    MODEL `mgmt467-71800.flights_data.pre_departure_engineered_model`,\n",
            "    (SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    CASE\n",
            "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
            "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
            "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
            "        ELSE 'long_delay'\n",
            "    END AS dep_delay_bucket,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            ")\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da998c1e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `evaluate_engineered_model_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the evaluation metrics as a Pandas DataFrame and display them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a7b0529"
      },
      "source": [
        "# Task\n",
        "Build and evaluate an engineered BigQuery ML logistic regression model for predicting flight diversions, incorporating a bucketized departure delay feature, and then compare its performance against the pre-departure baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4515306f"
      },
      "source": [
        "## Evaluate Engineered Model Performance (AUC, Log_Loss)\n",
        "\n",
        "### Subtask:\n",
        "Use `ML.EVALUATE` to assess the engineered model's performance, focusing on Area Under the Curve (AUC) and log_loss. This will allow for comparison with the baseline model and provide insights into the impact of the new `dep_delay_bucket` feature.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca80a974"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the `evaluate_engineered_model_sql` using the BigQuery client to get the evaluation metrics as a Pandas DataFrame and display them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24568d0e",
        "outputId": "a7bbf834-cf3a-4370-ccf8-fbcef4efbee9"
      },
      "source": [
        "print('Evaluating BigQuery ML engineered model...')\n",
        "engineered_evaluation_results_df = bq.query(evaluate_engineered_model_sql).result().to_dataframe()\n",
        "print('Engineered model evaluation complete!')\n",
        "\n",
        "print(engineered_evaluation_results_df)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating BigQuery ML engineered model...\n",
            "Engineered model evaluation complete!\n",
            "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
            "0        1.0  0.000035  0.982807   0.00007  0.076117  0.784524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ccc312"
      },
      "source": [
        "## Generate Confusion Matrix for Engineered Model\n",
        "\n",
        "### Subtask:\n",
        "Calculate and display the confusion matrix for the engineered model at a classification threshold of 0.5 using `ML.CONFUSION_MATRIX`. This will provide insights into its true positives, true negatives, false positives, and false negatives, similar to the baseline analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94505063"
      },
      "source": [
        "**Reasoning**:\n",
        "Construct a BigQuery SQL query to generate the confusion matrix for the `pre_departure_engineered_model` using `ML.CONFUSION_MATRIX` with a classification threshold of 0.5, and store it in the `engineered_confusion_matrix_sql` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0296f2",
        "outputId": "fedb50e6-c921-40e1-9680-1b40c605ac81"
      },
      "source": [
        "engineered_confusion_matrix_sql = f\"\"\"SELECT\n",
        "  * FROM ML.CONFUSION_MATRIX(\n",
        "    MODEL `{PROJECT_ID}.flights_data.pre_departure_engineered_model`,\n",
        "    ({create_engineered_features_sql}),\n",
        "    STRUCT(0.5 AS threshold)\n",
        ")\"\"\"\n",
        "\n",
        "print(engineered_confusion_matrix_sql)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT\n",
            "  * FROM ML.CONFUSION_MATRIX(\n",
            "    MODEL `mgmt467-71800.flights_data.pre_departure_engineered_model`,\n",
            "    (SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    CASE\n",
            "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
            "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
            "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
            "        ELSE 'long_delay'\n",
            "    END AS dep_delay_bucket,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            "),\n",
            "    STRUCT(0.5 AS threshold)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8e227d"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `engineered_confusion_matrix_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the confusion matrix as a Pandas DataFrame and display it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4eda028",
        "outputId": "c65cfec2-df5a-4533-a882-0dbb78ebef3e"
      },
      "source": [
        "print('Generating engineered model confusion matrix...')\n",
        "engineered_confusion_matrix_df = bq.query(engineered_confusion_matrix_sql).result().to_dataframe()\n",
        "print('Engineered model confusion matrix generated!')\n",
        "\n",
        "print(engineered_confusion_matrix_df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating engineered model confusion matrix...\n",
            "Engineered model confusion matrix generated!\n",
            "   expected_label       _0  _1\n",
            "0             0.0  1629748   0\n",
            "1             1.0    28510   1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cf33853"
      },
      "source": [
        "## Interpretation of Confusion Matrix for Engineered Model\n",
        "\n",
        "### At a 0.5 threshold):\n",
        "\n",
        "- True Negatives (TN): `1629748` - The model correctly predicted a vast majority of non-diverted flights.\n",
        "- False Positives (FP): `0` - The model incorrectly predicted 0 flights as diverted when they were not. This is an improvement over the baseline model's 102 FPs, indicating perfect precision for positive predictions at this threshold.\n",
        "- False Negatives (FN): `28510` - The model incorrectly predicted 28,510 flights as not diverted when they actually were. This is a very high number, similar to the baseline, indicating extremely low recall for the positive class.\n",
        "- True Positives (TP): `1` - The model correctly identified only 1 actual diversion. This is a significant drop compared to the baseline's 30 TPs.\n",
        "\n",
        "The confusion matrix for the engineered model shows that while it achieves perfect precision (0 False Positives) at the 0.5 threshold, its ability to identify actual diversions (True Positives) has severely degraded, with only 1 TP. This results in an even lower recall (0.000035) than the baseline model (0.001052). The model is extremely conservative in predicting diversions, effectively missing almost all actual events. The addition of the `dep_delay_bucket` feature has not improved the model's ability to capture positive cases at this threshold; in fact, it has made it more cautious, leading to an even worse recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0caa7d3e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the engineered model's confusion matrix has been interpreted, the next step is to analyze its calibration by constructing a BigQuery SQL query to predict probabilities, bin them, and calculate average predicted probability and actual diversion rates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb0ec33a",
        "outputId": "4d36b050-c9e1-4071-aa24-33ac4ce0202d"
      },
      "source": [
        "engineered_calibration_sql = f\"\"\"WITH Predictions AS (\n",
        "    SELECT\n",
        "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
        "        Diverted\n",
        "    FROM\n",
        "        ML.PREDICT(\n",
        "            MODEL `{PROJECT_ID}.flights_data.pre_departure_engineered_model`,\n",
        "            ({create_engineered_features_sql})\n",
        "        )\n",
        "),\n",
        "BinnedPredictions AS (\n",
        "    SELECT\n",
        "        NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
        "        predicted_probability,\n",
        "        Diverted\n",
        "    FROM\n",
        "        Predictions\n",
        ")\n",
        "SELECT\n",
        "    probability_bin,\n",
        "    AVG(predicted_probability) AS avg_predicted_probability,\n",
        "    AVG(Diverted) AS actual_diversion_rate\n",
        "FROM\n",
        "    BinnedPredictions\n",
        "GROUP BY\n",
        "    probability_bin\n",
        "ORDER BY\n",
        "    probability_bin\n",
        "\"\"\"\n",
        "\n",
        "print(engineered_calibration_sql)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH Predictions AS (\n",
            "    SELECT\n",
            "        predicted_Diverted_probs[OFFSET(1)].prob AS predicted_probability,\n",
            "        Diverted\n",
            "    FROM\n",
            "        ML.PREDICT(\n",
            "            MODEL `mgmt467-71800.flights_data.pre_departure_engineered_model`,\n",
            "            (SELECT\n",
            "    Reporting_Airline AS carrier,\n",
            "    Distance,\n",
            "    CONCAT(Origin, '-', Dest) AS route,\n",
            "    Month,\n",
            "    DayOfWeek,\n",
            "    CASE\n",
            "        WHEN DepDelay <= 0 THEN 'no_delay'\n",
            "        WHEN DepDelay > 0 AND DepDelay <= 15 THEN 'short_delay'\n",
            "        WHEN DepDelay > 15 AND DepDelay <= 60 THEN 'medium_delay'\n",
            "        ELSE 'long_delay'\n",
            "    END AS dep_delay_bucket,\n",
            "    Diverted\n",
            "FROM\n",
            "    `flights_data.flights_raw`\n",
            "WHERE\n",
            "    Diverted IS NOT NULL\n",
            ")\n",
            "        )\n",
            "),\n",
            "BinnedPredictions AS (\n",
            "    SELECT\n",
            "        NTILE(10) OVER (ORDER BY predicted_probability) AS probability_bin,\n",
            "        predicted_probability,\n",
            "        Diverted\n",
            "    FROM\n",
            "        Predictions\n",
            ")\n",
            "SELECT\n",
            "    probability_bin,\n",
            "    AVG(predicted_probability) AS avg_predicted_probability,\n",
            "    AVG(Diverted) AS actual_diversion_rate\n",
            "FROM\n",
            "    BinnedPredictions\n",
            "GROUP BY\n",
            "    probability_bin\n",
            "ORDER BY\n",
            "    probability_bin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75f47ef0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `engineered_calibration_sql` has been constructed, I need to execute this SQL query using the BigQuery client to get the calibration metrics as a Pandas DataFrame and display them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dd91f6e",
        "outputId": "198316bb-ba8b-449a-92ff-5d2062ec4505"
      },
      "source": [
        "print('Analyzing engineered model calibration...')\n",
        "engineered_calibration_df = bq.query(engineered_calibration_sql).result().to_dataframe()\n",
        "print('Engineered model calibration analysis complete!')\n",
        "\n",
        "print(engineered_calibration_df)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing engineered model calibration...\n",
            "Engineered model calibration analysis complete!\n",
            "   probability_bin  avg_predicted_probability  actual_diversion_rate\n",
            "0                1                   0.934499               0.082780\n",
            "1                2                   0.967856               0.026733\n",
            "2                3                   0.977454               0.016131\n",
            "3                4                   0.983026               0.010409\n",
            "4                5                   0.986746               0.007767\n",
            "5                6                   0.989649               0.006284\n",
            "6                7                   0.991890               0.007309\n",
            "7                8                   0.993795               0.006712\n",
            "8                9                   0.995587               0.005813\n",
            "9               10                   0.997328               0.001996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0da4f66b"
      },
      "source": [
        "## Analyze Engineered Model Calibration\n",
        "\n",
        "The calibration analysis for the engineered model shows a similar pattern to the baseline model, but with some subtle differences:\n",
        "\n",
        "*   **Overconfidence continues**: For lower probability bins (e.g., bin 1: average predicted `0.934499`, actual `0.082780`), the model is still significantly overconfident, predicting very high probabilities for non-diversion while the actual diversion rate is much lower. This indicates a consistent overestimation of certainty.\n",
        "*   **Slightly different magnitudes**: While the overall trend of overconfidence persists, the specific values in each bin have changed slightly compared to the baseline. For instance, in bin 1, the engineered model's `avg_predicted_probability` is slightly lower than the baseline (0.934499 vs 0.939825), and the `actual_diversion_rate` is also slightly lower (0.082780 vs 0.083425). This suggests that the addition of `dep_delay_bucket` has not fundamentally fixed the calibration issue, but rather slightly altered the probability distribution.\n",
        "*   **Highest confidence, still low actuals**: In the highest probability bin (bin 10: average predicted `0.997328`, actual `0.001996`), the model is highly confident in its prediction of non-diversion, but the actual diversion rate remains very low. The actual rate here is also marginally lower than the baseline's bin 10 (0.001996 vs 0.002050).\n",
        "\n",
        "In summary, the engineered model, even with the addition of the `dep_delay_bucket` feature, continues to exhibit poor calibration. It remains overly confident in its predictions, particularly for the negative class (non-diversion), where its predicted probabilities are consistently higher than the observed actual diversion rates. The new feature did not significantly improve the model's ability to provide well-calibrated probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94bdb058"
      },
      "source": [
        "## Analyze Engineered Model Calibration\n",
        "\n",
        "The calibration analysis for the engineered model shows a similar pattern to the baseline model, but with some subtle differences:\n",
        "\n",
        "*   **Overconfidence continues**: For lower probability bins (e.g., bin 1: average predicted `0.934499`, actual `0.082780`), the model is still significantly overconfident, predicting very high probabilities for non-diversion while the actual diversion rate is much lower. This indicates a consistent overestimation of certainty.\n",
        "*   **Slightly different magnitudes**: While the overall trend of overconfidence persists, the specific values in each bin have changed slightly compared to the baseline. For instance, in bin 1, the engineered model's `avg_predicted_probability` is slightly lower than the baseline (0.934499 vs 0.939825), and the `actual_diversion_rate` is also slightly lower (0.082780 vs 0.083425). This suggests that the addition of `dep_delay_bucket` has not fundamentally fixed the calibration issue, but rather slightly altered the probability distribution.\n",
        "*   **Highest confidence, still low actuals**: In the highest probability bin (bin 10: average predicted `0.997328`, actual `0.001996`), the model is highly confident in its prediction of non-diversion, but the actual diversion rate remains very low. The actual rate here is also marginally lower than the baseline's bin 10 (0.001996 vs 0.002050).\n",
        "\n",
        "In summary, the engineered model, even with the addition of the `dep_delay_bucket` feature, continues to exhibit poor calibration. It remains overly confident in its predictions, particularly for the negative class (non-diversion), where its predicted probabilities are consistently higher than the observed actual diversion rates. The new feature did not significantly improve the model's ability to provide well-calibrated probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65a36208"
      },
      "source": [
        "## Compare Engineered Model to Baseline\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance metrics (AUC, log_loss, confusion matrix insights, and calibration) of the `pre_departure_engineered_model` against the `pre_departure_baseline_model`. Highlight any improvements or degradations in performance due to the new engineered features, especially the bucketized `dep_delay`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6381044"
      },
      "source": [
        "## Compare Engineered Model to Baseline\n",
        "\n",
        "### Subtask:\n",
        "Compare the performance metrics (AUC, log_loss, confusion matrix insights, and calibration) of the `pre_departure_engineered_model` against the `pre_departure_baseline_model`. Highlight any improvements or degradations in performance due to the new engineered features, especially the bucketized `dep_delay`.\n",
        "\n",
        "### Comparison and Insights\n",
        "\n",
        "**1. AUC (Area Under the Curve):**\n",
        "\n",
        "*   **Baseline Model AUC:** 0.785921\n",
        "*   **Engineered Model AUC:** 0.784524\n",
        "\n",
        "The AUC for the engineered model is slightly lower than that of the baseline model (0.784524 vs 0.785921). This marginal decrease suggests that the addition of the `dep_delay_bucket` feature did not improve the model's overall ability to distinguish between positive and negative classes. The discriminative power remained largely the same, or even slightly degraded.\n",
        "\n",
        "**2. Log_Loss:**\n",
        "\n",
        "*   **Baseline Model Log_Loss:** 0.076178\n",
        "*   **Engineered Model Log_Loss:** 0.076117\n",
        "\n",
        "The engineered model shows a slightly lower log_loss (0.076117 vs 0.076178) compared to the baseline. A lower log_loss indicates that the engineered model's predicted probabilities are marginally closer to the actual outcomes. While a small improvement, it's not substantial enough to suggest a significant practical advantage on its own.\n",
        "\n",
        "**3. Confusion Matrix (at a 0.5 threshold):**\n",
        "\n",
        "| Metric              | Baseline Model       | Engineered Model     | Change/Implication                                                                                                      |\n",
        "| :------------------ | :------------------- | :------------------- | :---------------------------------------------------------------------------------------------------------------------- |\n",
        "| **True Negatives (TN)** | 1,629,646            | 1,629,748            | Slight increase (+102). Both models are excellent at identifying non-diverted flights.                                  |\n",
        "| **False Positives (FP)**| 102                  | 0                    | Significant decrease (-102). Engineered model has perfect precision (no false alarms) at this threshold.                |\n",
        "| **False Negatives (FN)**| 28,481               | 28,510               | Slight increase (+29). Both models struggle significantly with recall, missing most actual diversions.                  |\n",
        "| **True Positives (TP)** | 30                   | 1                    | Drastic decrease (-29). The engineered model identified almost no actual diversions, leading to extremely low recall.   |\n",
        "| **Recall (Diverted)**   | 0.001052 (30/28511)  | 0.000035 (1/28511)   | Severely degraded. The engineered model is even more conservative, effectively missing almost all actual diversion events. |\n",
        "| **Precision (Diverted)**| 0.227273 (30/132)    | 1.0 (1/1)            | Improved significantly. Engineered model has perfect precision at 0.5 threshold due to 0 FPs.                           |\n",
        "\n",
        "**Impact of `dep_delay_bucket`:**\n",
        "\n",
        "The addition of the `dep_delay_bucket` feature had a detrimental effect on the model's ability to identify actual diversions (True Positives) at the 0.5 threshold. While it eliminated False Positives, leading to perfect precision, it severely reduced True Positives from 30 to just 1. This resulted in an even lower recall for the engineered model, making it practically useless for identifying diversions. The model became overly cautious and conservative in its predictions for the positive class.\n",
        "\n",
        "**4. Calibration Analysis:**\n",
        "\n",
        "Both models exhibit similar calibration issues:\n",
        "\n",
        "*   **Baseline Calibration:**\n",
        "    *   For the lowest probability bin (bin 1), `avg_predicted_probability` is 0.939825, while `actual_diversion_rate` is 0.083425.\n",
        "    *   For the highest probability bin (bin 10), `avg_predicted_probability` is 0.997795, while `actual_diversion_rate` is 0.002050.\n",
        "\n",
        "*   **Engineered Calibration:**\n",
        "    *   For the lowest probability bin (bin 1), `avg_predicted_probability` is 0.934499, while `actual_diversion_rate` is 0.082780.\n",
        "    *   For the highest probability bin (bin 10), `avg_predicted_probability` is 0.997328, while `actual_diversion_rate` is 0.001996.\n",
        "\n",
        "Both models consistently show a significant overestimation of the probability of non-diversion (`avg_predicted_probability` is much higher than `actual_diversion_rate` across most bins). The engineered model's calibration profile remains largely similar to the baseline, suggesting that the `dep_delay_bucket` feature did not significantly improve or worsen the model's calibration; the problem of overconfidence persists.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "While the engineered model achieved a slightly better log_loss and perfect precision at the 0.5 threshold, the introduction of the `dep_delay_bucket` feature ultimately led to a **less effective model** for predicting flight diversions. The drastic drop in True Positives (from 30 to 1) and the resulting abysmal recall demonstrate that the engineered model is excessively conservative, missing almost all actual diversion events. This makes it unsuitable as an early warning system. The slight change in AUC and similar calibration issues further confirm that the feature engineering, at least in this form, did not yield a more practical or reliable model. Future efforts should explore other feature engineering techniques or modeling approaches that can better capture the rare diversion events and improve recall without sacrificing too much precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3150b0d0"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Conclude the task by summarizing the findings for the engineered model, comparing it comprehensively to the baseline model, and discussing whether the feature engineering led to a more effective model for diversion risk prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36aa1e7a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The feature engineering, specifically the addition of the `dep_delay_bucket` feature, did **not** lead to a more effective model for diversion risk prediction. While it achieved perfect precision (0 false positives) at a 0.5 threshold and a marginally lower log_loss, it drastically reduced the model's ability to identify actual diversions (True Positives dropped from 30 to 1), resulting in severely degraded recall (from 0.001052 to 0.000035). This made the model excessively conservative and practically ineffective as an early warning system.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The engineered model showed a slightly lower Area Under the Curve (AUC) of 0.784524 compared to the baseline model's 0.785921, indicating a marginal decrease in its overall discriminative power.\n",
        "*   The engineered model achieved a marginally better log_loss of 0.076117, slightly lower than the baseline's 0.076178, suggesting its predicted probabilities were slightly closer to actual outcomes.\n",
        "*   At a 0.5 classification threshold, the engineered model exhibited perfect precision (1.0) by reducing False Positives from 102 in the baseline to 0.\n",
        "*   However, the engineered model drastically reduced True Positives from 30 (baseline) to only 1, leading to a severe degradation in recall for the 'Diverted' class from 0.001052 to 0.000035.\n",
        "*   Both the baseline and engineered models exhibited similar calibration issues, consistently overestimating the probability of non-diversion across most probability bins (e.g., for bin 1, engineered model's average predicted probability was 0.934499 versus an actual diversion rate of 0.082780). The `dep_delay_bucket` feature did not significantly improve the model's calibration.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The current feature engineering approach, using `dep_delay_bucket`, made the model excessively conservative, prioritizing the avoidance of false positives over the detection of actual diversions. This is problematic for an early warning system where identifying as many true diversions as possible is crucial.\n",
        "*   Future work should explore alternative feature engineering strategies or model architectures that can improve recall for the positive class (diversions) without completely sacrificing precision. This might involve different ways of encoding `dep_delay`, investigating other relevant features, or adjusting model thresholds and loss functions to better handle the imbalanced nature of diversion events.\n"
      ]
    }
  ]
}